{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43dfc1f0",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Введение в машинное обучение. Обучение с учителем. Задача регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b0580",
   "metadata": {},
   "source": [
    "<b>Традиционное предупреждение для всех лабораторных работ:</b> перед обучением моделей необходимо выполнить предварительную обработку данных, которая <b>обязательно</b> включает в себя:\n",
    "- заполнение пропущенных значений (рекомедуется логика заполнения пропусков на основе типа данных, которая использовалась в РГР по Практикуму);\n",
    "- преобразование категориальных признаков в числовые (используйте one-hot кодирование или map; используйте знания с Практикума)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d9e23",
   "metadata": {},
   "source": [
    "Предобработка может включать в себя другие действия, но выполнение описанных выше действий обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aab9d1",
   "metadata": {},
   "source": [
    "Сделайте это один раз и сохраните в отдельный csv файл, а потом его используйте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053af5b",
   "metadata": {},
   "source": [
    "<b>Выполните следующие задания:</b>\n",
    "- загрузите датасет для регрессии, выделите целевой признак и предикторы, разбейте данные на обучающую и тестовую выборку;\n",
    "- решите задачу регрессии на ваших данных с использованием моделей sklearn (линейная регрессия + L1, L2), для моделей с регуляризациями подберите гиперпараметр;\n",
    "- решите задачу регрессии на ваших данных с использованием моделей sklearn (полиномиальная регрессия + L1, L2), для моделей с регуляризациями подберите гиперпараметр;\n",
    "- вычислите значения метрик $R^2$, MAE, MSE, RMSE, MAPE для всех обученных моделей; выберите лучшую модель;\n",
    "- самостоятельно реализуйте (желательно в виде класса) модель линейной регрессии с регуляризацией (можете выбрать L1 или L2);\n",
    "- самостоятельно реализуйте вычисление всех используемых метрик (в виде функций, принимающих два аргумента);\n",
    "- обучите вашу модель линейной регрессии на ваших данных; оцените качество с помощью реализованных вами метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f500beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14befecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-29 16:40:21</td>\n",
       "      <td>2016-02-29 16:47:01</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-11 23:35:37</td>\n",
       "      <td>2016-03-11 23:53:57</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-21 17:59:33</td>\n",
       "      <td>2016-02-21 18:26:48</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-05 09:44:31</td>\n",
       "      <td>2016-01-05 10:03:32</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-17 06:42:23</td>\n",
       "      <td>2016-02-17 06:56:31</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0        2.0  2016-02-29 16:40:21  2016-02-29 16:47:01                1   \n",
       "1        1.0  2016-03-11 23:35:37  2016-03-11 23:53:57                2   \n",
       "2        2.0  2016-02-21 17:59:33  2016-02-21 18:26:48                2   \n",
       "3        2.0  2016-01-05 09:44:31  2016-01-05 10:03:32                6   \n",
       "4        1.0  2016-02-17 06:42:23  2016-02-17 06:56:31                1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.953918        40.778873         -73.963875         40.771164   \n",
       "1        -73.988312        40.731743         -73.994751         40.694931   \n",
       "2        -73.997314        40.721458         -73.948029         40.774918   \n",
       "3        -73.961670        40.759720         -73.956779         40.780628   \n",
       "4        -74.017120        40.708469         -73.988182         40.740631   \n",
       "\n",
       "   trip_duration  \n",
       "0            400  \n",
       "1           1100  \n",
       "2           1635  \n",
       "3           1141  \n",
       "4            848  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"../data/trip_duration_task.csv\")\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90cb46f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 729322 entries, 0 to 729321\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   vendor_id          727135 non-null  float64\n",
      " 1   pickup_datetime    729322 non-null  object \n",
      " 2   dropoff_datetime   729322 non-null  object \n",
      " 3   passenger_count    729322 non-null  int64  \n",
      " 4   pickup_longitude   729322 non-null  float64\n",
      " 5   pickup_latitude    727475 non-null  float64\n",
      " 6   dropoff_longitude  729322 non-null  float64\n",
      " 7   dropoff_latitude   729322 non-null  float64\n",
      " 8   trip_duration      729322 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 50.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5b51477",
   "metadata": {},
   "source": [
    "Предобработка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73570f23",
   "metadata": {},
   "source": [
    "1) Убрал строки с null-value в столбце \"vendor_id\"\n",
    "2) Заполнил строки с null-value в столбце \"pickup_latitude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf0c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 727135 entries, 0 to 729321\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   vendor_id          727135 non-null  float64\n",
      " 1   pickup_datetime    727135 non-null  object \n",
      " 2   dropoff_datetime   727135 non-null  object \n",
      " 3   passenger_count    727135 non-null  int64  \n",
      " 4   pickup_longitude   727135 non-null  float64\n",
      " 5   pickup_latitude    727135 non-null  float64\n",
      " 6   dropoff_longitude  727135 non-null  float64\n",
      " 7   dropoff_latitude   727135 non-null  float64\n",
      " 8   trip_duration      727135 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 55.5+ MB\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 466. GiB for an array with shape (707290, 707290) and data type int8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mpickup_latitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfillna(data[\u001b[39m'\u001b[39m\u001b[39mpickup_latitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m data\u001b[39m.\u001b[39minfo()\n\u001b[0;32m----> 4\u001b[0m data_onehot \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mget_dummies(data, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbyte\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m data_onehot\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m../data/trip_duration_task_mod.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m data_onehot\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:192\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m     with_dummies \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39mdtypes_to_encode)]\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m (col, pre, sep) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_to_encode\u001b[39m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[1;32m    191\u001b[0m     \u001b[39m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     dummy \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[1;32m    193\u001b[0m         col[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    194\u001b[0m         prefix\u001b[39m=\u001b[39;49mpre,\n\u001b[1;32m    195\u001b[0m         prefix_sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m    196\u001b[0m         dummy_na\u001b[39m=\u001b[39;49mdummy_na,\n\u001b[1;32m    197\u001b[0m         sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[1;32m    198\u001b[0m         drop_first\u001b[39m=\u001b[39;49mdrop_first,\n\u001b[1;32m    199\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m     with_dummies\u001b[39m.\u001b[39mappend(dummy)\n\u001b[1;32m    202\u001b[0m result \u001b[39m=\u001b[39m concat(with_dummies, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:311\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m concat(sparse_series, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    309\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[39m# take on axis=1 + transpose to ensure ndarray layout is column-major\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     dummy_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(number_of_cols, dtype\u001b[39m=\u001b[39;49mdtype)\u001b[39m.\u001b[39mtake(codes, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\n\u001b[1;32m    313\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dummy_na:\n\u001b[1;32m    314\u001b[0m         \u001b[39m# reset NaN GH4446\u001b[39;00m\n\u001b[1;32m    315\u001b[0m         dummy_mat[codes \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/numpy/lib/twodim_base.py:215\u001b[0m, in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m M \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     M \u001b[39m=\u001b[39m N\n\u001b[0;32m--> 215\u001b[0m m \u001b[39m=\u001b[39m zeros((N, M), dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m M:\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 466. GiB for an array with shape (707290, 707290) and data type int8"
     ]
    }
   ],
   "source": [
    "data.dropna(how='any', subset=['vendor_id'], inplace=True) \n",
    "data['pickup_latitude'].fillna(data['pickup_latitude'].mean().astype(float), inplace=True)\n",
    "data.info()\n",
    "data_onehot = pd.get_dummies(data, dtype='byte')\n",
    "data_onehot.to_csv('../data/trip_duration_task_mod.csv')\n",
    "data_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec420378",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['trip_duration']\n",
    "X = data.drop(['trip_duration'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd3390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          400\n",
       "1         1100\n",
       "2         1635\n",
       "3         1141\n",
       "4          848\n",
       "          ... \n",
       "729317     296\n",
       "729318     315\n",
       "729319     673\n",
       "729320     447\n",
       "729321    1224\n",
       "Name: trip_duration, Length: 727135, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dbe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-29 16:40:21</td>\n",
       "      <td>2016-02-29 16:47:01</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-11 23:35:37</td>\n",
       "      <td>2016-03-11 23:53:57</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-21 17:59:33</td>\n",
       "      <td>2016-02-21 18:26:48</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-05 09:44:31</td>\n",
       "      <td>2016-01-05 10:03:32</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-17 06:42:23</td>\n",
       "      <td>2016-02-17 06:56:31</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729317</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-21 13:29:38</td>\n",
       "      <td>2016-05-21 13:34:34</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.965919</td>\n",
       "      <td>40.789780</td>\n",
       "      <td>-73.952637</td>\n",
       "      <td>40.789181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-22 00:43:11</td>\n",
       "      <td>2016-02-22 00:48:26</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.996666</td>\n",
       "      <td>40.737434</td>\n",
       "      <td>-74.001320</td>\n",
       "      <td>40.731911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729319</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-15 18:56:48</td>\n",
       "      <td>2016-04-15 19:08:01</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.997849</td>\n",
       "      <td>40.761696</td>\n",
       "      <td>-74.001488</td>\n",
       "      <td>40.741207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729320</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-06-19 09:50:47</td>\n",
       "      <td>2016-06-19 09:58:14</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006706</td>\n",
       "      <td>40.708244</td>\n",
       "      <td>-74.013550</td>\n",
       "      <td>40.713814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729321</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-01 17:24:16</td>\n",
       "      <td>2016-01-01 17:44:40</td>\n",
       "      <td>4</td>\n",
       "      <td>-74.003342</td>\n",
       "      <td>40.743839</td>\n",
       "      <td>-73.945847</td>\n",
       "      <td>40.712841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0             2.0  2016-02-29 16:40:21  2016-02-29 16:47:01                1   \n",
       "1             1.0  2016-03-11 23:35:37  2016-03-11 23:53:57                2   \n",
       "2             2.0  2016-02-21 17:59:33  2016-02-21 18:26:48                2   \n",
       "3             2.0  2016-01-05 09:44:31  2016-01-05 10:03:32                6   \n",
       "4             1.0  2016-02-17 06:42:23  2016-02-17 06:56:31                1   \n",
       "...           ...                  ...                  ...              ...   \n",
       "729317        2.0  2016-05-21 13:29:38  2016-05-21 13:34:34                2   \n",
       "729318        1.0  2016-02-22 00:43:11  2016-02-22 00:48:26                1   \n",
       "729319        1.0  2016-04-15 18:56:48  2016-04-15 19:08:01                1   \n",
       "729320        1.0  2016-06-19 09:50:47  2016-06-19 09:58:14                1   \n",
       "729321        2.0  2016-01-01 17:24:16  2016-01-01 17:44:40                4   \n",
       "\n",
       "        pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
       "0             -73.953918        40.778873         -73.963875         40.771164  \n",
       "1             -73.988312        40.731743         -73.994751         40.694931  \n",
       "2             -73.997314        40.721458         -73.948029         40.774918  \n",
       "3             -73.961670        40.759720         -73.956779         40.780628  \n",
       "4             -74.017120        40.708469         -73.988182         40.740631  \n",
       "...                  ...              ...                ...               ...  \n",
       "729317        -73.965919        40.789780         -73.952637         40.789181  \n",
       "729318        -73.996666        40.737434         -74.001320         40.731911  \n",
       "729319        -73.997849        40.761696         -74.001488         40.741207  \n",
       "729320        -74.006706        40.708244         -74.013550         40.713814  \n",
       "729321        -74.003342        40.743839         -73.945847         40.712841  \n",
       "\n",
       "[727135 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f581bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ded22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((581708, 8), (581708,), (145427, 8), (145427,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17d5ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2016-01-22 00:02:43'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lr \u001b[39m=\u001b[39m LinearRegression()\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m    657\u001b[0m     X,\n\u001b[1;32m    658\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    662\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/python_machine_learning/venv/lib/python3.10/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2016-01-22 00:02:43'"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "336122a42b05141550a7f4791af30c335b516ad8eb087c768aba9720a82cd308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
